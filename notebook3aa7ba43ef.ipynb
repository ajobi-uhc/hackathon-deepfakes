{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 77151,
          "databundleVersionId": 8401844,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "notebook3aa7ba43ef",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'automathon-deepfake:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F77151%2F8401844%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240430%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240430T195037Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2f1af147451b61b9b37c274c0838d06d4c37cd281c5fa932291056fddf077c8fa77d3518e94bb97ad48aed973721d1c4fae5dae770addcfe382a284dccc6617038998dbdb970ced483d1211740cdd97b00437d32ab487747da390dc816925e5cda1708eec85ff3549d435b9da2590d13c3554a428dc26d9ab732ef373ca2c6657760eed8d98395ec796a37b42924f44cf6a135ecce303af6e41f497ece2def08abdf7e704190288ba3ed15f62a58156e593f3b65559f326c584d8884d30a865dd01ca1c8dff2726778adab2b12fd7076663d1708d70e1f5e1cb9e9fdd921db0d4adf99b3763c6398b5c6ad71261d33f8f1b1c0bf5e24f051cf3e5ddb91b2e2fc'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZq7nlAWjyov",
        "outputId": "79b3ad19-9b49-4fb4-c69d-5576d37fb09a"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading automathon-deepfake, 3919757882 bytes compressed\n",
            "[==================================================] 3919757882 bytes downloaded\n",
            "Downloaded and uncompressed: automathon-deepfake\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fnmatch\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import asyncio\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import io\n",
        "import cv2\n",
        "import glob\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cETzI-OgpDTu",
        "outputId": "049f7abb-49a4-4cd9-b937-a90667e69dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_video_path = \"/kaggle/input/automathon-deepfake/dataset/experimental_dataset\"\n",
        "dataset_metadata_path = \"/kaggle/input/automathon-deepfake/dataset/experimental_dataset/metadata.json\"\n",
        "\n",
        "video_files = glob.glob(dataset_video_path)\n",
        "\n",
        "df_labels = pd.read_json(dataset_metadata_path, orient='index')\n",
        "df_labels.reset_index(inplace=True)\n",
        "df_labels.columns = ['Filename', 'Label']\n",
        "df_labels['label_value'] = np.where(df_labels['Label'] == 'real', 1, 0)"
      ],
      "metadata": {
        "id": "J3WpsDz93mSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class video_dataset(Dataset):\n",
        "    def __init__(self, df, base_video_path, transform=None, sequence_length=60):\n",
        "        \"\"\"\n",
        "        Initializes the dataset.\n",
        "        :param df: DataFrame containing 'Filename' and 'label_value'\n",
        "        :param transform: Transformations to be applied to each frame\n",
        "        :param sequence_length: Number of frames to extract from each video\n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        self.sequence_length = sequence_length\n",
        "        self.base_path = base_video_path\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Fetch the video path and label from the DataFrame\n",
        "        video_path = self.df.iloc[idx]['Filename']\n",
        "        label = self.df.iloc[idx]['label_value']\n",
        "\n",
        "        # Extract frames from the video\n",
        "        frames = []\n",
        "        for i, frame in enumerate(self.frame_extract(self.base_path + \"/\" + video_path)):\n",
        "            if self.transform:\n",
        "                frame = self.transform(frame)\n",
        "            frames.append(frame)\n",
        "            if len(frames) == self.sequence_length:\n",
        "                break\n",
        "\n",
        "        # Stack the frames\n",
        "        frames = torch.stack(frames)\n",
        "        frames = frames[:self.sequence_length]\n",
        "        return frames, label\n",
        "\n",
        "    def frame_extract(self, path):\n",
        "        \"\"\"\n",
        "        Generator to extract frames from a given video path.\n",
        "        \"\"\"\n",
        "        print(\"Path of video\", path)\n",
        "        vidObj = cv2.VideoCapture(path)\n",
        "        success, image = vidObj.read()\n",
        "        while success:\n",
        "            yield image\n",
        "            success, image = vidObj.read()"
      ],
      "metadata": {
        "id": "w26bYHftqNtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((112, 112)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_data = video_dataset(df_labels, dataset_video_path, transform=frame_transforms)\n",
        "train_loader = DataLoader(train_data,batch_size = 4,shuffle = True)"
      ],
      "metadata": {
        "id": "V_ukJS7csr3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for frames, labels in train_loader:\n",
        "    print(\"Batch shape:\", frames.shape)  # Expected: (batch_size, sequence_length, channels, height, width)\n",
        "    print(\"Labels shape:\", labels.shape)  # Expected: (batch_size,)\n",
        "    break  # Only check the first batch for quick verification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ayMDx-c8T_o",
        "outputId": "a4aaec51-3d29-4d31-d9b9-f42119a11eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path of video /kaggle/input/automathon-deepfake/dataset/experimental_dataset/ozgsdfnksv.mp4\n",
            "Path of video /kaggle/input/automathon-deepfake/dataset/experimental_dataset/mshibrgvlv.mp4\n",
            "Path of video /kaggle/input/automathon-deepfake/dataset/experimental_dataset/oaaoicrccb.mp4\n",
            "Path of video /kaggle/input/automathon-deepfake/dataset/experimental_dataset/iclluvbprk.mp4\n",
            "Batch shape: torch.Size([4, 60, 3, 112, 112])\n",
            "Labels shape: torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "snURH97u8fNH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}